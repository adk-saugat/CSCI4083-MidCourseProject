{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UfTL2NBk8CAg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DxjvCKDS7jJi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_train_dataset(file_path:str):\n",
        "    train_df = pd.read_csv(file_path)\n",
        "    X_train = train_df.drop(\"label\", axis=1)\n",
        "    y_train = train_df[\"label\"].values\n",
        "    return X_train, y_train\n",
        "\n",
        "def load_test_dataset(file_path:str):\n",
        "    test_df = pd.read_csv(file_path)\n",
        "    X_test = test_df.drop(\"label\", axis=1)\n",
        "    y_test = test_df[\"label\"].values\n",
        "    return X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Build the model\n",
        "def build_mlp(input_dim=784, n_classes=25, hidden_units=(256, 128, 64, 24), activation=\"relu\", **kwargs):\n",
        "    \"\"\"Build a sequential MLP with configurable hidden layers and activation.\"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(input_dim,)))\n",
        "    for units in hidden_units:\n",
        "        model.add(tf.keras.layers.Dense(units, activation=activation, **kwargs))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(n_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "W8gJpD8G7wyh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##train the model\n",
        "X, Y = load_train_dataset(\"/content/drive/MyDrive/sign_mnist_train.csv\")\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        "    start_from_epoch=0\n",
        ")\n",
        "# build the model\n",
        "model = build_mlp()\n",
        "\n",
        "# Correctly assign the outputs of train_test_split\n",
        "model.fit(x_train, y_train, validation_data =(x_val, y_val) ,epochs=100, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO-q0QvH8YRZ",
        "outputId": "b86127cf-547e-404f-95ec-5d22616845cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - accuracy: 0.1571 - loss: 2.9641 - val_accuracy: 0.3010 - val_loss: 2.2329\n",
            "Epoch 2/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3459 - loss: 2.0262 - val_accuracy: 0.2836 - val_loss: 2.3053\n",
            "Epoch 3/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3382 - loss: 1.9980 - val_accuracy: 0.3300 - val_loss: 2.0356\n",
            "Epoch 4/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3687 - loss: 1.9207 - val_accuracy: 0.3706 - val_loss: 1.9638\n",
            "Epoch 5/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3523 - loss: 1.9172 - val_accuracy: 0.2825 - val_loss: 2.3741\n",
            "Epoch 6/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3567 - loss: 1.9096 - val_accuracy: 0.4872 - val_loss: 1.4935\n",
            "Epoch 7/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3866 - loss: 1.8157 - val_accuracy: 0.4711 - val_loss: 1.5859\n",
            "Epoch 8/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3965 - loss: 1.7907 - val_accuracy: 0.5052 - val_loss: 1.3989\n",
            "Epoch 9/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4229 - loss: 1.7173 - val_accuracy: 0.4081 - val_loss: 1.8061\n",
            "Epoch 10/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4169 - loss: 1.7120 - val_accuracy: 0.6090 - val_loss: 1.1517\n",
            "Epoch 11/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4085 - loss: 1.7267 - val_accuracy: 0.3797 - val_loss: 1.9179\n",
            "Epoch 12/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4048 - loss: 1.7411 - val_accuracy: 0.4893 - val_loss: 1.4169\n",
            "Epoch 13/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4170 - loss: 1.7102 - val_accuracy: 0.4413 - val_loss: 1.6305\n",
            "Epoch 14/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4229 - loss: 1.6958 - val_accuracy: 0.3564 - val_loss: 1.9579\n",
            "Epoch 15/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 1.8413 - val_accuracy: 0.5218 - val_loss: 1.3979\n",
            "Epoch 16/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3888 - loss: 1.8042 - val_accuracy: 0.5606 - val_loss: 1.3547\n",
            "Epoch 17/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3947 - loss: 1.7923 - val_accuracy: 0.5740 - val_loss: 1.2847\n",
            "Epoch 18/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3975 - loss: 1.7877 - val_accuracy: 0.4802 - val_loss: 1.4888\n",
            "Epoch 19/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4048 - loss: 1.7503 - val_accuracy: 0.4786 - val_loss: 1.5802\n",
            "Epoch 20/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4017 - loss: 1.7476 - val_accuracy: 0.4642 - val_loss: 1.5821\n",
            "Epoch 21/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4120 - loss: 1.7408 - val_accuracy: 0.5549 - val_loss: 1.2439\n",
            "Epoch 22/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4080 - loss: 1.7266 - val_accuracy: 0.3965 - val_loss: 1.8098\n",
            "Epoch 23/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4172 - loss: 1.7052 - val_accuracy: 0.5391 - val_loss: 1.3735\n",
            "Epoch 24/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4160 - loss: 1.7096 - val_accuracy: 0.6270 - val_loss: 1.1170\n",
            "Epoch 25/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4148 - loss: 1.7318 - val_accuracy: 0.2726 - val_loss: 2.5917\n",
            "Epoch 26/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3448 - loss: 1.9110 - val_accuracy: 0.2597 - val_loss: 2.3077\n",
            "Epoch 27/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3483 - loss: 1.9160 - val_accuracy: 0.4218 - val_loss: 1.6677\n",
            "Epoch 28/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3589 - loss: 1.8659 - val_accuracy: 0.4689 - val_loss: 1.5321\n",
            "Epoch 29/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3492 - loss: 1.8839 - val_accuracy: 0.5886 - val_loss: 1.2647\n",
            "Epoch 30/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3563 - loss: 1.8830 - val_accuracy: 0.2391 - val_loss: 2.1842\n",
            "Epoch 31/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2671 - loss: 2.1414 - val_accuracy: 0.2868 - val_loss: 2.1540\n",
            "Epoch 32/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2654 - loss: 2.1226 - val_accuracy: 0.2743 - val_loss: 2.3436\n",
            "Epoch 33/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2739 - loss: 2.1148 - val_accuracy: 0.4298 - val_loss: 1.6139\n",
            "Epoch 34/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2817 - loss: 2.0939 - val_accuracy: 0.2734 - val_loss: 2.1596\n",
            "Epoch 35/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2808 - loss: 2.0778 - val_accuracy: 0.2513 - val_loss: 2.4254\n",
            "Epoch 36/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2878 - loss: 2.0770 - val_accuracy: 0.3256 - val_loss: 1.8395\n",
            "Epoch 37/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3017 - loss: 2.0402 - val_accuracy: 0.3522 - val_loss: 1.8326\n",
            "Epoch 38/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3476 - loss: 1.9244 - val_accuracy: 0.3619 - val_loss: 1.7601\n",
            "Epoch 39/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3647 - loss: 1.8414 - val_accuracy: 0.4378 - val_loss: 1.4470\n",
            "Epoch 40/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3714 - loss: 1.8200 - val_accuracy: 0.5121 - val_loss: 1.3251\n",
            "Epoch 41/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3730 - loss: 1.8275 - val_accuracy: 0.5043 - val_loss: 1.3720\n",
            "Epoch 42/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3614 - loss: 1.8395 - val_accuracy: 0.5178 - val_loss: 1.3164\n",
            "Epoch 43/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3786 - loss: 1.8005 - val_accuracy: 0.4451 - val_loss: 1.5353\n",
            "Epoch 44/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3808 - loss: 1.7947 - val_accuracy: 0.4374 - val_loss: 1.5469\n",
            "Epoch 45/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3806 - loss: 1.8004 - val_accuracy: 0.5742 - val_loss: 1.1998\n",
            "Epoch 46/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3779 - loss: 1.7951 - val_accuracy: 0.4924 - val_loss: 1.3853\n",
            "Epoch 47/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3843 - loss: 1.7684 - val_accuracy: 0.4252 - val_loss: 1.7760\n",
            "Epoch 48/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3821 - loss: 1.7601 - val_accuracy: 0.5434 - val_loss: 1.2548\n",
            "Epoch 49/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3813 - loss: 1.7820 - val_accuracy: 0.5631 - val_loss: 1.2034\n",
            "Epoch 50/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3852 - loss: 1.7630 - val_accuracy: 0.5409 - val_loss: 1.1987\n",
            "Epoch 51/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3870 - loss: 1.7620 - val_accuracy: 0.5606 - val_loss: 1.1649\n",
            "Epoch 52/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3946 - loss: 1.7493 - val_accuracy: 0.3462 - val_loss: 1.7948\n",
            "Epoch 53/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3881 - loss: 1.7624 - val_accuracy: 0.5469 - val_loss: 1.2197\n",
            "Epoch 54/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3942 - loss: 1.7375 - val_accuracy: 0.3602 - val_loss: 1.9752\n",
            "Epoch 55/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3883 - loss: 1.7562 - val_accuracy: 0.4966 - val_loss: 1.3494\n",
            "Epoch 56/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3937 - loss: 1.7413 - val_accuracy: 0.5868 - val_loss: 1.1362\n",
            "Epoch 57/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3956 - loss: 1.7388 - val_accuracy: 0.1821 - val_loss: 3.3640\n",
            "Epoch 58/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3867 - loss: 1.7540 - val_accuracy: 0.1797 - val_loss: 4.5264\n",
            "Epoch 59/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3760 - loss: 1.7706 - val_accuracy: 0.3355 - val_loss: 1.8545\n",
            "Epoch 60/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3947 - loss: 1.7330 - val_accuracy: 0.4495 - val_loss: 1.5132\n",
            "Epoch 61/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3907 - loss: 1.7258 - val_accuracy: 0.3708 - val_loss: 2.0320\n",
            "Epoch 62/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3994 - loss: 1.7298 - val_accuracy: 0.3772 - val_loss: 1.8221\n",
            "Epoch 63/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4025 - loss: 1.6980 - val_accuracy: 0.6185 - val_loss: 1.0829\n",
            "Epoch 64/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4026 - loss: 1.7113 - val_accuracy: 0.6083 - val_loss: 1.1292\n",
            "Epoch 65/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3946 - loss: 1.7231 - val_accuracy: 0.4083 - val_loss: 2.0457\n",
            "Epoch 66/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4105 - loss: 1.6775 - val_accuracy: 0.3296 - val_loss: 1.9208\n",
            "Epoch 67/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3920 - loss: 1.7400 - val_accuracy: 0.5156 - val_loss: 1.3140\n",
            "Epoch 68/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3936 - loss: 1.7183 - val_accuracy: 0.4491 - val_loss: 1.4594\n",
            "Epoch 69/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4075 - loss: 1.6885 - val_accuracy: 0.4234 - val_loss: 1.5138\n",
            "Epoch 70/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3681 - loss: 1.8365 - val_accuracy: 0.3588 - val_loss: 1.7606\n",
            "Epoch 71/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2844 - loss: 2.0495 - val_accuracy: 0.3070 - val_loss: 1.9757\n",
            "Epoch 72/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3011 - loss: 2.0107 - val_accuracy: 0.3340 - val_loss: 1.8064\n",
            "Epoch 73/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3043 - loss: 1.9933 - val_accuracy: 0.4311 - val_loss: 1.5598\n",
            "Epoch 74/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2983 - loss: 2.0070 - val_accuracy: 0.4866 - val_loss: 1.4240\n",
            "Epoch 75/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3044 - loss: 1.9661 - val_accuracy: 0.4551 - val_loss: 1.4377\n",
            "Epoch 76/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3039 - loss: 2.0198 - val_accuracy: 0.3027 - val_loss: 1.9092\n",
            "Epoch 77/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3049 - loss: 1.9762 - val_accuracy: 0.2349 - val_loss: 2.4357\n",
            "Epoch 78/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3096 - loss: 1.9701 - val_accuracy: 0.2693 - val_loss: 2.2740\n",
            "Epoch 79/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3118 - loss: 1.9711 - val_accuracy: 0.3402 - val_loss: 1.7992\n",
            "Epoch 80/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3145 - loss: 1.9678 - val_accuracy: 0.3779 - val_loss: 1.6236\n",
            "Epoch 81/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3124 - loss: 1.9764 - val_accuracy: 0.2258 - val_loss: 2.4514\n",
            "Epoch 82/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3088 - loss: 1.9678 - val_accuracy: 0.4048 - val_loss: 1.5368\n",
            "Epoch 83/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3075 - loss: 1.9732 - val_accuracy: 0.2683 - val_loss: 1.9135\n",
            "Epoch 84/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.3156 - loss: 1.9575 - val_accuracy: 0.2176 - val_loss: 2.7557\n",
            "Epoch 85/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3058 - loss: 2.0284 - val_accuracy: 0.4424 - val_loss: 1.4878\n",
            "Epoch 86/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3232 - loss: 1.9497 - val_accuracy: 0.3874 - val_loss: 1.6102\n",
            "Epoch 87/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3040 - loss: 1.9974 - val_accuracy: 0.2378 - val_loss: 2.2314\n",
            "Epoch 88/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3075 - loss: 1.9816 - val_accuracy: 0.2444 - val_loss: 2.1733\n",
            "Epoch 89/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3079 - loss: 1.9695 - val_accuracy: 0.3180 - val_loss: 1.9161\n",
            "Epoch 90/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3092 - loss: 1.9589 - val_accuracy: 0.3100 - val_loss: 2.0259\n",
            "Epoch 91/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3038 - loss: 1.9903 - val_accuracy: 0.3367 - val_loss: 1.8417\n",
            "Epoch 92/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3169 - loss: 1.9401 - val_accuracy: 0.2568 - val_loss: 2.0773\n",
            "Epoch 93/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3186 - loss: 1.9303 - val_accuracy: 0.2775 - val_loss: 2.0458\n",
            "Epoch 94/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3103 - loss: 1.9737 - val_accuracy: 0.4316 - val_loss: 1.6058\n",
            "Epoch 95/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3101 - loss: 1.9415 - val_accuracy: 0.2306 - val_loss: 2.5723\n",
            "Epoch 96/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3063 - loss: 1.9558 - val_accuracy: 0.2244 - val_loss: 3.2120\n",
            "Epoch 97/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1961 - loss: 2.7283 - val_accuracy: 0.3101 - val_loss: 2.2605\n",
            "Epoch 98/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2065 - loss: 2.3704 - val_accuracy: 0.2579 - val_loss: 2.2138\n",
            "Epoch 99/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2157 - loss: 2.3239 - val_accuracy: 0.2613 - val_loss: 2.2095\n",
            "Epoch 100/100\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2086 - loss: 2.3757 - val_accuracy: 0.2280 - val_loss: 2.2612\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x799389fd5a60>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "model.save(\"multilayer_model.keras\")\n",
        "\n",
        "print(\"Model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl2nNJcK9ur3",
        "outputId": "5e6ab2b5-3736-4891-eb06-4b8de83eb74e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    }
  ]
}